{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\cobyw\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import convtas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data = tf.data.Dataset.load('tensors/tensor_dataset_small')\n",
    "x_batches = [tens[0] for tens in tf_data]\n",
    "y_batches = [tens[1] for tens in tf_data]\n",
    "x_batches = np.array(x_batches)\n",
    "y_batches = np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\cobyw\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x00000157CD4822A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x00000157CD4C0AE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "cnn = convtas.ConvTasNet()\n",
    "output = cnn(x_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvTasNet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder (Encoder)           multiple                  8704      \n",
      "                                                                 \n",
      " Separator (Separator)       multiple                  6154368   \n",
      "                                                                 \n",
      " Decoder (Decoder)           multiple                  8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6171280 (23.54 MB)\n",
      "Trainable params: 6171280 (23.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([200, 4, 40, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting The audio from the model.\n",
    "\n",
    "Okay so we finally have our output from the model, but what does any of this mean? The best way to interpret it is to look at the shape of the output which is in this format: $(M, C, K, L)$ where:\n",
    "\n",
    "- $M$ = 100; Batch number, remember each batch observation is 2 tensors each one correlating to the left/right audio channel.\n",
    "- $C$ = 4; Source number, each number correlates to drums, bass, other, and vocals respectively.\n",
    "- $K$ = 40; Index/number of overlapping chunks of waveform.\n",
    "- $L$ = 16; Length of a chunk/sample of data. For this study we will refer to these as chunks.\n",
    "- Another important parameter to know is 'overlap', which is the amount of samples the chunks overlap to their adjacent chunk. In this audio batch, the overlap = 8.\n",
    "\n",
    "The main question is how do i combine the overlapping chunks back into an approximation of the audio signal while trying to keep some level of each chunks' features in the estimated audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
